{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Compare the results with normal holdout validation\n",
    "- Apply 5-fold cross validation for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n",
    "\n",
    "# adding target to boston_features data for kfolds coming up later\n",
    "boston_features[\"target\"] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "\n",
    "Perform a train-test-split with a test set of 0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and apply the model to the make test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(ypred, ytrue):\n",
    "    \"\"\"\n",
    "    formula = 1/n * sum(fi-yi); where fi = model_value, yi=true_value\n",
    "    input\n",
    "    ypred: array of predictions\n",
    "    ytrue: array of true values (with respect to our ypred)\n",
    "    \n",
    "    output\n",
    "    mse: float\n",
    "    \"\"\"\n",
    "    N = ypred.shape[0]\n",
    "    # print(N)\n",
    "    return float(np.sum(np.square(ypred-ytrue)))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the residuals and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.674460248887016 25.888097770631557\n",
      "4.546917664625896 5.088034765076941\n"
     ]
    }
   ],
   "source": [
    "yhat_train = model.predict(xtrain)\n",
    "yhat_test  = model.predict(xtest)\n",
    "\n",
    "# residuals\n",
    "train_residuals = yhat_train - ytrain\n",
    "test_residuals  = yhat_test  - ytest\n",
    "\n",
    "# mse error\n",
    "mse_train = mse(yhat_train, ytrain)\n",
    "mse_test  = mse(yhat_test,  ytest)\n",
    "\n",
    "# print results\n",
    "print(mse_train, mse_test) # mean squared error\n",
    "print(np.sqrt(mse_train), np.sqrt(mse_test)) # root mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: let's build it from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cross-validation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function k-folds that splits a dataset into k evenly sized pieces.\n",
    "If the full dataset is not divisible by k, make the first few folds one larger then later ones.\n",
    "\n",
    "We want the folds to be a list of subsets of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    # Force data as pandas dataframe\n",
    "    # add 1 to fold size to account for leftovers\n",
    "    data = pd.DataFrame(data) # dataframe\n",
    "    num_observations = len(data) # number of rows\n",
    "    fold_size = num_observations//k # floor division 3.82 -> 3\n",
    "    leftovers = num_observations%k # remainder after division by k\n",
    "    folds = []\n",
    "    start_obs = 0\n",
    "    for fold_n in range(1,k+1): # loop from 1, 2, ..., k\n",
    "        if fold_n <= leftovers:\n",
    "            # Fold Size will be 1 larger to account for leftovers\n",
    "            fold =  data.iloc[start_obs : start_obs+fold_size+1] # slicing rows from 0 to k+1\n",
    "            folds.append(fold)\n",
    "            start_obs +=  fold_size + 1 # setting start to fold_size + 1\n",
    "        else:\n",
    "            fold =  data.iloc[start_obs : start_obs+fold_size] \n",
    "            folds.append(fold)\n",
    "            start_obs +=  fold_size\n",
    "            \n",
    "    return folds \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it to the Boston Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to concatenate the data again\n",
    "# folding on boston_features data since it also includes target values\n",
    "folds = kfolds(boston_features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE       DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  0.542096  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  0.623954  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  0.623954  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  0.707895  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  0.707895  3.0  222.0   \n",
       "\n",
       "   PTRATIO         B     LSTAT  target  \n",
       "0     15.3  1.000000 -1.275260    24.0  \n",
       "1     17.8  1.000000 -0.263711    21.6  \n",
       "2     17.8  0.989737 -1.627858    34.7  \n",
       "3     18.7  0.994276 -2.153192    33.4  \n",
       "4     18.7  1.000000 -1.162114    36.2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice this includes target\n",
    "folds[0].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a linear regression for each fold, and calculate the training and test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform linear regression on each and calculate the training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.91857867030196, 17.361583277713574, 15.543427264673552, 11.040378388195787, 17.23404426556593]\n",
      "[13.04498602423651, 14.64079170968883, 24.8580642761322, 55.300233948565, 19.218460110193845]\n"
     ]
    }
   ],
   "source": [
    "test_errs = []\n",
    "train_errs = []\n",
    "k=5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split in train and test for the fold\n",
    "    train_set = pd.concat([fold for i, fold in enumerate(folds) if i!=n]) # train folds are folds!=n\n",
    "    test_set = folds[n] # current fold is test fold\n",
    "    \n",
    "    # split X and y data\n",
    "    xtr = train_set.loc[:, train_set.columns!='target'] # xtrain\n",
    "    ytr = train_set.target # ytrain\n",
    "    xte = test_set.loc[:, test_set.columns!='target'] # xtest\n",
    "    yte = test_set.target #ytest\n",
    "    # print(ytr.shape, yte.shape, train_set.shape, test_set.shape) # use if you want to check that the shapes match\n",
    "    \n",
    "    # init/fit linreg\n",
    "    linreg = LinearRegression() # optional you can also just use 'model' \n",
    "                                # from above to fit the current model on a new data set\n",
    "    linreg.fit(xtr, ytr)\n",
    "    \n",
    "    # get yhats for train and test\n",
    "    yhat_tr = linreg.predict(xtr)\n",
    "    yhat_te = linreg.predict(xte)\n",
    "    \n",
    "    # calculate residuals\n",
    "    tr_res = yhat_tr - ytr\n",
    "    te_res = yhat_te - yte\n",
    "    \n",
    "    # append the mean sq err to their respective lists\n",
    "    train_errs.append(np.mean(tr_res.astype(float)**2)) # mean sqr err appended to list\n",
    "    test_errs.append(np.mean(te_res.astype(float)**2))  # mean sqr err appended to list\n",
    "\n",
    "    \n",
    "print(train_errs)\n",
    "print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Now, let's perform 5-fold cross-validation to get the mean squared error through scikit-learn. Let's have a look at the five individual MSEs and explain what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error # calcualte mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score # will calculate cross_val_score same as for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of the MSE over the 5 cross-validations and compare and contrast with the result from the train-test-split case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating X and y with 5 folds read the docstring below if you want cv and scoring explained\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=\"neg_mean_squared_error\") # cv = number of folds, scoring = #type of score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.40514492, -17.4440168 , -37.03271139, -58.27954385,\n",
       "       -26.09798876])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_5_results # Notice this is similar to test_errs above, except negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docstring for cross_val_score\n",
    "\"\"\"\n",
    "Evaluate a score by cross-validation\n",
    "\n",
    "Read more in the :ref:`User Guide <cross_validation>`.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "estimator : estimator object implementing 'fit'\n",
    "    The object to use to fit the data.\n",
    "\n",
    "X : array-like\n",
    "    The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "y : array-like, optional, default: None\n",
    "    The target variable to try to predict in the case of\n",
    "    supervised learning.\n",
    "\n",
    "groups : array-like, with shape (n_samples,), optional\n",
    "    Group labels for the samples used while splitting the dataset into\n",
    "    train/test set.\n",
    "\n",
    "scoring : string, callable or None, optional, default: None\n",
    "    A string (see model evaluation documentation) or\n",
    "    a scorer callable object / function with signature\n",
    "    ``scorer(estimator, X, y)``.\n",
    "\n",
    "cv : int, cross-validation generator or an iterable, optional\n",
    "    Determines the cross-validation splitting strategy.\n",
    "    Possible inputs for cv are:\n",
    "\n",
    "    - None, to use the default 3-fold cross validation,\n",
    "    - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
    "    - An object to be used as a cross-validation generator.\n",
    "    - An iterable yielding train, test splits.\n",
    "\n",
    "    For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
    "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "    other cases, :class:`KFold` is used.\n",
    "\n",
    "    Refer :ref:`User Guide <cross_validation>` for the various\n",
    "    cross-validation strategies that can be used here.\n",
    "\n",
    "n_jobs : integer, optional\n",
    "    The number of CPUs to use to do the computation. -1 means\n",
    "    'all CPUs'.\n",
    "\n",
    "verbose : integer, optional\n",
    "    The verbosity level.\n",
    "\n",
    "fit_params : dict, optional\n",
    "    Parameters to pass to the fit method of the estimator.\n",
    "\n",
    "pre_dispatch : int, or string, optional\n",
    "    Controls the number of jobs that get dispatched during parallel\n",
    "    execution. Reducing this number can be useful to avoid an\n",
    "    explosion of memory consumption when more jobs get dispatched\n",
    "    than CPUs can process. This parameter can be:\n",
    "\n",
    "        - None, in which case all the jobs are immediately\n",
    "          created and spawned. Use this for lightweight and\n",
    "          fast-running jobs, to avoid delays due to on-demand\n",
    "          spawning of the jobs\n",
    "\n",
    "        - An int, giving the exact number of total jobs that are\n",
    "          spawned\n",
    "\n",
    "        - A string, giving an expression as a function of n_jobs,\n",
    "          as in '2*n_jobs'\n",
    "\n",
    "Returns\n",
    "-------\n",
    "scores : array of float, shape=(len(list(cv)),)\n",
    "    Array of scores of the estimator for each run of the cross validation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on k-fold crossvalidation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
